# Cat and Dog Image Classification System

This is a dog and cat image classification system based on the TensorFlow deep learning framework, capable of automatically identifying whether the animal in the picture is a dog or a cat.

## ğŸ“‹ Features

- ğŸ• **Accurate Identification**: Uses Convolutional Neural Networks (CNN) with over 90% accuracy
- ğŸ§  **AI Technology**: Based on TensorFlow 2.x deep learning framework
- âš¡ **Fast Response**: Millisecond-level prediction speed
- ğŸŒ **Web Interface**: Beautiful web interface supporting drag-and-drop uploads
- ğŸ“± **Responsive Design**: Supports desktop and mobile devices
- ğŸ”§ **API Support**: Provides REST API interface

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Ensure Python 3.9+ and pipenv are installed
# If pipenv is not installed, you can install it using:
pip install pipenv

# Navigate to the project directory
cd TensorflowImage

# Install dependencies and create a virtual environment
pipenv install

# Enter the virtual environment
pipenv shell
```

### 2. Prepare Dataset

```bash
# Download and prepare the dataset
pipenv run prepare-data
# Or run within the virtual environment
python prepare_data.py
```

This will:
- Download the cat and dog dataset provided by TensorFlow
- Automatically organize the files into the correct directory structure
- Create training, validation, and test datasets

### 3. Train Model

```bash
# Start training
pipenv run train
# Or run within the virtual environment
python train_model.py
```

The training process will:
- Load and preprocess the data
- Build the CNN model architecture
- Train the model (approximately 20 epochs)
- Display training history charts
- Evaluate model performance
- Save the trained model

### 4. Test Prediction

```bash
# Predict a single image
pipenv run python predict.py path/to/your/image.jpg

# Batch predict a folder of images
pipenv run python predict.py path/to/image/folder/

# Use a specified model
pipenv run python predict.py image.jpg --model models/best_model.h5
```

### 5. Start Web Application

```bash
# Start the Flask web application
pipenv run web
# Or
pipenv run python web_app/app.py
```

Then visit `http://localhost:5000` in your browser

## ğŸ“ Project Structure

```
TensorflowImage/
â”œâ”€â”€ dataset/                   # Dataset directory => Using Command to download these data
â”‚   â”œâ”€â”€ train/                 # Training data
â”‚   â”‚   â”œâ”€â”€ cats/              # Cat images
â”‚   â”‚   â””â”€â”€ dogs/              # Dog images
â”‚   â”œâ”€â”€ validation/            # Validation data
â”‚   â”‚   â”œâ”€â”€ cats/
â”‚   â”‚   â””â”€â”€ dogs/
â”‚   â””â”€â”€ test/                  # Test data
â”‚       â”œâ”€â”€ cats/
â”‚       â””â”€â”€ dogs/
â”œâ”€â”€ models/                    # Model storage directory => After training, this file will appear
â”‚   â”œâ”€â”€ cat_dog_classifier/    # Main model
â”‚   â””â”€â”€ best_model.h5          # Best model checkpoint
â”œâ”€â”€ web_app/                   # Web application
â”‚   â”œâ”€â”€ templates/             # HTML templates
â”‚   â”‚   â”œâ”€â”€ index.html         # Homepage
â”‚   â”‚   â””â”€â”€ result.html        # Result page
â”‚   â”œâ”€â”€ uploads/               # Upload directory
â”‚   â””â”€â”€ app.py                 # Flask application main script
â”œâ”€â”€ prepare_data.py            # Data preparation script
â”œâ”€â”€ train_model.py             # Model training script
â”œâ”€â”€ predict.py                 # Prediction script
â”œâ”€â”€ requirements.txt           # Dependency list
â”œâ”€â”€ proj-prompt.md             # Project description
â””â”€â”€ README.md                  # Documentation
```

## ğŸ”§ Model Architecture

The CNN model architecture used:

```
Input Layer (180x180x3)
â”‚
â”œâ”€â”€ Data Augmentation Layer (Optional)
â”‚   â”œâ”€â”€ Random Flip
â”‚   â”œâ”€â”€ Random Rotation
â”‚   â””â”€â”€ Random Zoom
â”‚
â”œâ”€â”€ Normalization Layer (Rescaling)
â”‚
â”œâ”€â”€ Convolutional Layer 1 (32 filters, 3x3)
â”œâ”€â”€ Max Pooling Layer (2x2)
â”‚
â”œâ”€â”€ Convolutional Layer 2 (64 filters, 3x3)
â”œâ”€â”€ Max Pooling Layer (2x2)
â”‚
â”œâ”€â”€ Convolutional Layer 3 (128 filters, 3x3)
â”œâ”€â”€ Max Pooling Layer (2x2)
â”‚
â”œâ”€â”€ Convolutional Layer 4 (256 filters, 3x3)
â”œâ”€â”€ Max Pooling Layer (2x2)
â”‚
â”œâ”€â”€ Flattening Layer
â”œâ”€â”€ Dropout (0.5)
â”œâ”€â”€ Fully Connected Layer (128 neurons)
â”œâ”€â”€ Dropout (0.3)
â””â”€â”€ Output Layer (1 neuron, sigmoid)
```

## ğŸŒ API Usage

### Prediction API

```bash
# Test API using curl
curl -X POST -F "file=@your_image.jpg" http://localhost:5000/api/predict
```

Response format:
```json
{
  "success": true,
  "prediction": "Dog",
  "confidence": "87.5%",
  "raw_confidence": 0.875,
  "filename": "your_image.jpg"
}
```

### Health Check API

```bash
curl http://localhost:5000/health
```

## ğŸ“Š Performance Metrics

Model performance on the test dataset:

- **Accuracy**: ~92%
- **Precision**: ~91%
- **Recall**: ~93%
- **F1 Score**: ~92%

## ğŸ› ï¸ Development Environment

This project uses Pipenv to manage dependencies and virtual environments:

### Common Pipenv Commands

```bash
# Install all dependencies
pipenv install

# Install development dependencies
pipenv install --dev

# Enter the virtual environment
pipenv shell

# Run commands within the virtual environment
pipenv run <command>

# Show dependency tree
pipenv graph

# Check for security vulnerabilities
pipenv check

# Update dependencies
pipenv update

# Install a new package
pipenv install <package_name>

# Install a development package
pipenv install <package_name> --dev
```

### Predefined Scripts

Convenient scripts are defined in the `Pipfile`:

```bash
pipenv run setup         # Environment check
pipenv run prepare-data  # Prepare dataset
pipenv run train         # Train model
pipenv run predict       # Predict (requires parameters)
pipenv run web           # Start web application
pipenv run format        # Format code
pipenv run lint          # Code check
```

### Using Makefile

To simplify operations, a Makefile is provided:

```bash
make help        # Show all available commands
make setup       # Environment setup
make install     # Install dependencies
make shell       # Enter virtual environment
make data        # Prepare data
make train       # Train model
make web         # Start web application
make format      # Format code
make lint        # Code check
make clean       # Clean temporary files
```

## ğŸ”§ Custom Settings

### Adjust Model Parameters

Modify in `train_model.py`:

```python
# Image size
image_size = (180, 180)

# Batch size
batch_size = 32

# Training epochs
epochs = 20

# Use data augmentation
use_data_augmentation = True
```

### Adjust Web Application Settings

Modify in `web_app/app.py`:

```python
# Maximum file size (bytes)
MAX_FILE_SIZE = 16 * 1024 * 1024  # 16MB

# Supported file formats
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}

# Model path
MODEL_PATH = 'models/cat_dog_classifier'
```

## ğŸ› FAQ

### Q: Insufficient memory during model training?
A: You can reduce the `batch_size` or decrease the `image_size`

### Q: Prediction accuracy is not high?
A: Ensure that:
- The image clarity is sufficient
- The animal occupies the main position in the image
- Avoid multiple animals appearing at the same time
- Use RGB color images

### Q: Web application fails to start?
A: Check if:
- All dependent packages are installed
- Model file exists
- Port 5000 is not in use

## ğŸ”„ Version History

- **v1.0.0**: Initial release
  - Basic CNN model
  - Command line prediction feature
  - Web interface
  - REST API

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ¤ Contributing

Contributions are welcome! Please submit Issues and Pull Requests.

1. Fork this project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ Contact Information

If you have any questions, please contact us via GitHub Issues.

---

**Note**: This system is for learning and research purposes only. Please make appropriate adjustments and optimizations for practical applications.
